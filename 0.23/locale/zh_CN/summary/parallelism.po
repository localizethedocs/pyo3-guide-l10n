msgid ""
msgstr ""
"Project-Id-Version: PyO3 user guide\n"
"POT-Creation-Date: 2025-12-16T11:33:41Z\n"
"PO-Revision-Date: \n"
"Last-Translator: \n"
"Language-Team: \n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Language: zh_CN\n"
"Plural-Forms: nplurals=1; plural=0;\n"

#: src/parallelism.md:1
msgid "Parallelism"
msgstr ""

#: src/parallelism.md:3
msgid ""
"CPython has the infamous [Global Interpreter Lock](https://docs.python.org/3/"
"glossary.html#term-global-interpreter-lock) (GIL), which prevents several "
"threads from executing Python bytecode in parallel. This makes threading in "
"Python a bad fit for [CPU-bound](https://en.wikipedia.org/wiki/CPU-bound) "
"tasks and often forces developers to accept the overhead of multiprocessing. "
"There is an experimental \"free-threaded\" version of CPython 3.13 that does "
"not have a GIL, see the PyO3 docs on [free-threaded Python](./free-threading."
"md) for more information about that."
msgstr ""

#: src/parallelism.md:5
msgid ""
"In PyO3 parallelism can be easily achieved in Rust-only code. Let's take a "
"look at our [word-count](https://github.com/PyO3/pyo3/blob/main/examples/"
"word-count/src/lib.rs) example, where we have a `search` function that "
"utilizes the [rayon](https://github.com/rayon-rs/rayon) crate to count words "
"in parallel."
msgstr ""

#: src/parallelism.md:9
msgid "// These traits let us use `par_lines` and `map`.\n"
msgstr ""

#: src/parallelism.md:13
msgid "/// Count the occurrences of needle in line, case insensitive\n"
msgstr ""

#: src/parallelism.md:17 src/parallelism.md:39 src/parallelism.md:59
msgid "' '"
msgstr ""

#: src/parallelism.md:34
msgid ""
"But let's assume you have a long running Rust function which you would like "
"to execute several times in parallel. For the sake of example let's take a "
"sequential version of the word count:"
msgstr ""

#: src/parallelism.md:52
msgid ""
"To enable parallel execution of this function, the [`Python::allow_threads`]"
"(https://pyo3.rs/main/doc/pyo3/marker/struct.Python.html#method."
"allow_threads) method can be used to temporarily release the GIL, thus "
"allowing other Python threads to run. We then have a function exposed to the "
"Python runtime which calls `search_sequential` inside a closure passed to "
"[`Python::allow_threads`](https://pyo3.rs/main/doc/pyo3/marker/struct.Python."
"html#method.allow_threads) to enable true parallelism:"
msgstr ""

#: src/parallelism.md:76
msgid ""
"Now Python threads can use more than one CPU core, resolving the limitation "
"which usually makes multi-threading in Python only good for IO-bound tasks:"
msgstr ""

#: src/parallelism.md:93
msgid "Benchmark"
msgstr ""

#: src/parallelism.md:95
msgid ""
"Let's benchmark the `word-count` example to verify that we really did unlock "
"parallelism with PyO3."
msgstr ""

#: src/parallelism.md:97
msgid "We are using `pytest-benchmark` to benchmark four word count functions:"
msgstr ""

#: src/parallelism.md:99
msgid "Pure Python version"
msgstr ""

#: src/parallelism.md:100
msgid "Rust parallel version"
msgstr ""

#: src/parallelism.md:101
msgid "Rust sequential version"
msgstr ""

#: src/parallelism.md:102
msgid "Rust sequential version executed twice with two Python threads"
msgstr ""

#: src/parallelism.md:104
msgid ""
"The benchmark script can be found [here](https://github.com/PyO3/pyo3/blob/"
"main/examples/word-count/tests/test_word_count.py), and we can run `nox` in "
"the `word-count` folder to benchmark these functions."
msgstr ""

#: src/parallelism.md:106
msgid ""
"While the results of the benchmark of course depend on your machine, the "
"relative results should be similar to this (mid 2020):"
msgstr ""

#: src/parallelism.md:118
msgid ""
"You can see that the Python threaded version is not much slower than the "
"Rust sequential version, which means compared to an execution on a single "
"CPU core the speed has doubled."
msgstr ""

#: src/parallelism.md:120
msgid "Sharing Python objects between Rust threads"
msgstr ""

#: src/parallelism.md:122
msgid ""
"In the example above we made a Python interface to a low-level rust "
"function, and then leveraged the python `threading` module to run the low-"
"level function in parallel. It is also possible to spawn threads in Rust "
"that acquire the GIL and operate on Python objects. However, care must be "
"taken to avoid writing code that deadlocks with the GIL in these cases."
msgstr ""

#: src/parallelism.md:128
msgid ""
"Note: This example is meant to illustrate how to drop and re-acquire the GIL "
"to avoid creating deadlocks. Unless the spawned threads subsequently release "
"the GIL or you are using the free-threaded build of CPython, you will not "
"see any speedups due to multi-threaded parallelism using `rayon` to "
"parallelize code that acquires and holds the GIL for the entire execution of "
"the spawned thread."
msgstr ""

#: src/parallelism.md:135
msgid ""
"In the example below, we share a `Vec` of User ID objects defined using the "
"`pyclass` macro and spawn threads to process the collection of data into a "
"`Vec` of booleans based on a predicate using a rayon parallel iterator:"
msgstr ""

#: src/parallelism.md:141
msgid "// These traits let us use int_par_iter and map\n"
msgstr ""

#: src/parallelism.md:163
msgid ""
"It's important to note that there is an `outer_py` GIL lifetime token as "
"well as an `inner_py` token. Sharing GIL lifetime tokens between threads is "
"not allowed and threads must individually acquire the GIL to access data "
"wrapped by a python object."
msgstr ""

#: src/parallelism.md:168
msgid ""
"It's also important to see that this example uses [`Python::allow_threads`]"
"(https://pyo3.rs/main/doc/pyo3/marker/struct.Python.html#method."
"allow_threads) to wrap the code that spawns OS threads via `rayon`. If this "
"example didn't use `allow_threads`, a rayon worker thread would block on "
"acquiring the GIL while a thread that owns the GIL spins forever waiting for "
"the result of the rayon thread. Calling `allow_threads` allows the GIL to be "
"released in the thread collecting the results from the worker threads. You "
"should always call `allow_threads` in situations that spawn worker threads, "
"but especially so in cases where worker threads need to acquire the GIL, to "
"prevent deadlocks."
msgstr ""
